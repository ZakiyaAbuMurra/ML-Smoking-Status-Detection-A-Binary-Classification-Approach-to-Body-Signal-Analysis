{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3637312,"sourceType":"datasetVersion","datasetId":2157551},{"sourceId":7485933,"sourceType":"datasetVersion","datasetId":4358063}],"dockerImageVersionId":30636,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import  GridSearchCV\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-01-26T13:44:43.349975Z","iopub.execute_input":"2024-01-26T13:44:43.350662Z","iopub.status.idle":"2024-01-26T13:44:43.355745Z","shell.execute_reply.started":"2024-01-26T13:44:43.350627Z","shell.execute_reply":"2024-01-26T13:44:43.354817Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_set = pd.read_csv('/kaggle/input/smoking/trainClean.csv')\ntest_set = pd.read_csv('/kaggle/input/smoking/testClean.csv')\nval_set = pd.read_csv('/kaggle/input/smoking/valClean.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-26T13:44:46.118031Z","iopub.execute_input":"2024-01-26T13:44:46.118727Z","iopub.status.idle":"2024-01-26T13:44:46.226387Z","shell.execute_reply.started":"2024-01-26T13:44:46.118687Z","shell.execute_reply":"2024-01-26T13:44:46.225427Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_train = train_set.iloc[:, :-1]\ny_train = train_set.iloc[:, -1]\nX_test = test_set.iloc[:, :-1]\ny_test = test_set.iloc[:, -1]\nX_val = val_set.iloc[:, :-1]\ny_val = val_set.iloc[:, -1]","metadata":{"execution":{"iopub.status.busy":"2024-01-26T13:44:49.153493Z","iopub.execute_input":"2024-01-26T13:44:49.154354Z","iopub.status.idle":"2024-01-26T13:44:49.162087Z","shell.execute_reply.started":"2024-01-26T13:44:49.154317Z","shell.execute_reply":"2024-01-26T13:44:49.161128Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n\n\ntrain_set = pd.read_csv('/kaggle/input/smoking/trainClean.csv')\ntest_set = pd.read_csv('/kaggle/input/smoking/testClean.csv')\nval_set = pd.read_csv('/kaggle/input/smoking/valClean.csv')\n\nX_train = train_set.iloc[:, :-1]\ny_train = train_set.iloc[:, -1]\nX_test = test_set.iloc[:, :-1]\ny_test = test_set.iloc[:, -1]\nX_val = val_set.iloc[:, :-1]\ny_val = val_set.iloc[:, -1]\n# Define the RandomForestClassifier\nrf_classifier = RandomForestClassifier(random_state=42)\n\n# Define the parameter grid to search\nparam_grid = {\n    'n_estimators': [50, 100, 150, 200],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10, 20],\n    'min_samples_leaf': [1, 2, 4, 8],\n}\n\n# Use SMOTE for handling imbalanced data\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Create a custom scoring metric (e.g., F1-score) for cross-validation\nscoring = {'precision': make_scorer(precision_score),\n           'recall': make_scorer(recall_score),\n           'f1_score': make_scorer(f1_score)}\n\n# Create the StratifiedKFold cross-validator\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Create the GridSearchCV object\ngrid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, scoring=scoring,\n                           cv=cv, refit='f1_score', verbose=2, n_jobs=-1)\n\n# Fit the model using the resampled training set\ngrid_search.fit(X_train_resampled, y_train_resampled)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\n\n# Evaluate the best model on the validation set\nbest_model = grid_search.best_estimator_\ny_val_pred = best_model.predict(X_val)\n\n# Evaluate performance metrics on the validation set\nprecision = precision_score(y_val, y_val_pred)\nrecall = recall_score(y_val, y_val_pred)\nf1 = f1_score(y_val, y_val_pred)\n\n# Print results on the validation set\nprint(\"Best Hyperparameters:\", best_params)\nprint(\"Precision on Validation Set:\", precision)\nprint(\"Recall on Validation Set:\", recall)\nprint(\"F1 Score on Validation Set:\", f1)\n\n# Calculate and print accuracy on the validation set\naccuracy_val = accuracy_score(y_val, y_val_pred)\nprint(\"Accuracy on Validation Set:\", accuracy_val)\n\n# Print confusion matrix on the validation set\nconf_matrix_val = confusion_matrix(y_val, y_val_pred)\nprint(\"\\nConfusion Matrix on Validation Set:\")\nprint(conf_matrix_val)\n\n# Evaluate the best model on the test set\ny_test_pred = best_model.predict(X_test)\n\n# Evaluate performance metrics on the test set\nprecision_test = precision_score(y_test, y_test_pred)\nrecall_test = recall_score(y_test, y_test_pred)\nf1_test = f1_score(y_test, y_test_pred)\n\n# Print results on the test set\nprint(\"\\nResults on Test Set:\")\nprint(\"Precision on Test Set:\", precision_test)\nprint(\"Recall on Test Set:\", recall_test)\nprint(\"F1 Score on Test Set:\", f1_test)\n\n# Calculate and print accuracy on the test set\naccuracy_test = accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy on Test Set:\", accuracy_test)\n\n# Print confusion matrix on the test set\nconf_matrix_test = confusion_matrix(y_test, y_test_pred)\nprint(\"\\nConfusion Matrix on Test Set:\")\nprint(conf_matrix_test)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_negative_class = sum(y_train == 0)\nnum_positive_class = sum(y_train == 1)\n\nclass_ratio = num_negative_class / num_positive_class\n\nprint(f'Class Ratio: {class_ratio}')","metadata":{"execution":{"iopub.status.busy":"2024-01-26T13:44:53.963629Z","iopub.execute_input":"2024-01-26T13:44:53.963984Z","iopub.status.idle":"2024-01-26T13:44:53.979342Z","shell.execute_reply.started":"2024-01-26T13:44:53.963954Z","shell.execute_reply":"2024-01-26T13:44:53.978364Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Class Ratio: 1.7253914988814318\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Create an XGBoost classifier\nxgb_classifier = xgb.XGBClassifier()\n\n# Define the parameter grid for hyperparameter tuning\nparam_grid = {\n    'max_depth': [3, 5, 7, 15],\n    'learning_rate': [10, 0.1, 0.01, 0.001],\n    'n_estimators': [50, 100, 200, 250],\n    'scale_pos_weight': [class_ratio, 2, 3, 5]\n}\n\n# Create the GridSearchCV object with 5-fold cross-validation\ngrid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n\n# Fit the model to the training data\ngrid_search.fit(X_train, y_train)\n\n# Print the best hyperparameters\nprint(\"Best Hyperparameters:\", grid_search.best_params_)\n\n# Get the best model\nbest_model = grid_search.best_estimator_\n\n# Evaluate the best model on the validation set\ny_val_pred = best_model.predict(X_val)\nval_accuracy = accuracy_score(y_val, y_val_pred)\nprint(\"Validation Accuracy:\", val_accuracy)\n\n# Print confusion matrix and classification report for validation set\nval_conf_matrix = confusion_matrix(y_val, y_val_pred)\nprint(\"Confusion Matrix (Validation):\\n\", val_conf_matrix)\n\nval_classification_report = classification_report(y_val, y_val_pred)\nprint(\"Classification Report (Validation):\\n\", val_classification_report)\n\n# Evaluate the best model on the test set\ny_test_pred = best_model.predict(X_test)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(\"Test Accuracy:\", test_accuracy)\n\n# Print confusion matrix and classification report for test set\ntest_conf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(\"Confusion Matrix (Test):\\n\", test_conf_matrix)\n\ntest_classification_report = classification_report(y_test, y_test_pred)\nprint(\"Classification Report (Test):\\n\", test_classification_report)","metadata":{"execution":{"iopub.status.busy":"2024-01-26T13:44:57.493015Z","iopub.execute_input":"2024-01-26T13:44:57.493888Z","iopub.status.idle":"2024-01-26T14:08:17.026640Z","shell.execute_reply.started":"2024-01-26T13:44:57.493857Z","shell.execute_reply":"2024-01-26T14:08:17.025452Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 250, 'scale_pos_weight': 2}\nValidation Accuracy: 0.8126645918123054\nConfusion Matrix (Validation):\n [[4313  970]\n [ 595 2476]]\nClassification Report (Validation):\n               precision    recall  f1-score   support\n\n           0       0.88      0.82      0.85      5283\n           1       0.72      0.81      0.76      3071\n\n    accuracy                           0.81      8354\n   macro avg       0.80      0.81      0.80      8354\nweighted avg       0.82      0.81      0.81      8354\n\nTest Accuracy: 0.8089537945894183\nConfusion Matrix (Test):\n [[4314  960]\n [ 636 2444]]\nClassification Report (Test):\n               precision    recall  f1-score   support\n\n           0       0.87      0.82      0.84      5274\n           1       0.72      0.79      0.75      3080\n\n    accuracy                           0.81      8354\n   macro avg       0.79      0.81      0.80      8354\nweighted avg       0.81      0.81      0.81      8354\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}